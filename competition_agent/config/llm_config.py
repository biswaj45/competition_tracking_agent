# LLM Configuration
LLM_CONFIG = {
    "model": "gpt-3.5-turbo",  # or "gpt-4" for higher quality
    "max_tokens": 500,
    "temperature": 0.3,  # Lower for more focused/consistent outputs
    "retry_attempts": 3,
    "timeout": 30  # seconds
}